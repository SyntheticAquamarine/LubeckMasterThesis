{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from os import walk\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "filepaths = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./OriginalDataset\", topdown=True):\n",
    "    for name in dirs:\n",
    "        if (bool(re.findall('\\d$', name)) == False):\n",
    "            Path = (root + '/' + name)\n",
    "            filepaths.append(re.sub('DaneMGR\\\\\\\\', 'DaneMGR/', Path))\n",
    "            \n",
    "\n",
    "filenameList = []\n",
    "fullPath = []\n",
    "for Path in filepaths:\n",
    "    for (dirpath, dirnames, filenames) in walk(Path):\n",
    "        for name in filenames:\n",
    "            if (bool(re.findall('fast_Unknown', name)) == True) and name not in filenameList:\n",
    "                NewName = re.sub('._CsvLog', 'CsvLog', name)\n",
    "                filenameList.append(NewName)\n",
    "                fullPath.append(Path + '/' + NewName)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(pd_data, window_size):\n",
    "    np_data = pd_data.to_numpy()\n",
    "    nb_timestamps, nb_sensors = np_data.shape\n",
    "    \n",
    "    #window_size = 100 # Size of the data segments, earlier there was the value of 100\n",
    "    timestamp_idx = 0 # Index along the timestamp dimension\n",
    "    segment_idx = 0 # Index for the segment dimension\n",
    "    \n",
    "    nb_segments = int(math.floor(nb_timestamps/window_size))\n",
    "    print(f'Starting segmentation with a window size of {window_size} resulting in {nb_segments} segments.')\n",
    "    data_to_save = np.zeros((nb_segments,window_size,nb_sensors),dtype=np.float32)\n",
    "\n",
    "    while segment_idx < nb_segments:\n",
    "        data_to_save[segment_idx] = np_data[timestamp_idx:timestamp_idx+window_size,:]\n",
    "        timestamp_idx += window_size\n",
    "        segment_idx += 1\n",
    "    return data_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 'N' #500000 #'N' # describes which rows multiplied by n should be taken into the dataset #If chosen parameter is N the rows will not get dropped\n",
    "fields = ['Infinity|RESP.ONLY_ONE_IN_GROUP [OHM]', 'Infinity|SPO2.SPO2_PULSE [COUNTS]']\n",
    "WindowSize = 100\n",
    "NumOfSensors = 2\n",
    "df_0 = np.zeros((1,WindowSize, NumOfSensors))\n",
    "df_1 = np.zeros((1,WindowSize, NumOfSensors))\n",
    "\n",
    "files_total = len(fullPath)\n",
    "i = 1\n",
    "for path in fullPath:\n",
    "    print(path)\n",
    "    df_local = pd.read_csv(path, sep = ',', encoding = 'UTF-8', usecols=fields)\n",
    "    df_local = df_local.interpolate()\n",
    "    if T != 'N':\n",
    "        df_local = df_local[df_local.index % T == 0] #Set to 2000 as 1 second is 20 observations\n",
    "    match = re.findall(\"/B/Csv\",path)\n",
    "    \n",
    "    df_segmented = segmentation(df_local, WindowSize)\n",
    "    \n",
    "    print(df_segmented)\n",
    "    print(df_segmented.shape)\n",
    "    print(sum(sum(np.isnan(df_segmented))))\n",
    "    \n",
    "    neo = re.findall('\\/([\\d]{1,2})\\/', path)\n",
    "    #print(neo)\n",
    "    #print(neo[0])\n",
    "    #neo2 = re.sub('\\/', '', neo[0])\n",
    "    \n",
    "\n",
    "    if bool(match) == True:\n",
    "        location_B = f'./CreatedFiles/Position_B/{neo[0]}.npy'\n",
    "        print(location_B)\n",
    "        np.save(location_B, df_segmented)\n",
    "        #df_1 = np.concatenate(df_segmented, axis = 1)\n",
    "        #print(df_1.shape)\n",
    "    else:\n",
    "        location_S = f'./CreatedFiles/Position_S/{neo[0]}.npy'\n",
    "        print(location_S)\n",
    "        np.save(location_S, df_segmented)\n",
    "        #df_0 = np.concatenate(df_segmented, axis = 0)\n",
    "        #print(df_0.shape)\n",
    "    #neo = re.findall('\\/([\\d]{1,2})\\/', path)\n",
    "    #df_local.insert(0,'neonate', str(neo))\n",
    "    #print(df_local)\n",
    "    print(f\"Imported file number: {i}, from files total: {files_total}, and that is {i*100/files_total:.2f}%\")\n",
    "    i+=1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "df_2 = np.zeros((1,WindowSize, NumOfSensors))\n",
    "print(df_2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
